{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apply' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33301/2833124335.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'hi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bye'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output of MultiDCP:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'apply' is not defined"
     ]
    }
   ],
   "source": [
    "text = map(str, ['hi', 5, 'bye'])\n",
    "print('Output of MultiDCP:{}'.format(\"\\n\".join(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'multidcp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31424/2883602536.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/utils'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmultidcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatareader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'multidcp'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch import save\n",
    "import numpy as np\n",
    "import argparse\n",
    "sys.path.insert(0, os.path.abspath('../module-subdirectory'))\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')) + '/models')\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')) + '/utils')\n",
    "import multidcp\n",
    "import datareader\n",
    "import metric\n",
    "import wandb\n",
    "import pdb\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from multidcp_ae_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid/home/joshua/MultiDCP/MultiDCP\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid/home/joshua/MultiDCP/MultiDCP'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid/home/joshua/MultiDCP/models\n"
     ]
    }
   ],
   "source": [
    " print(os.path.abspath('../models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch import save\n",
    "import numpy as np\n",
    "import argparse\n",
    "sys.path.insert(0, os.path.abspath('./models'))\n",
    "sys.path.insert(0, os.path.abspath('./utils'))\n",
    "import multidcp\n",
    "import datareader\n",
    "import metric\n",
    "import wandb\n",
    "import pdb\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from multidcp_ae_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoshroll\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.19 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/raid/home/joshua/MultiDCP/MultiDCP/wandb/run-20220624_162732-1ibtlufd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/joshroll/MultiDCP_AE_loss/runs/1ibtlufd\" target=\"_blank\">autumn-deluge-26</a></strong> to <a href=\"https://wandb.ai/joshroll/MultiDCP_AE_loss\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "USE_WANDB = True\n",
    "if USE_WANDB:\n",
    "    wandb.init(project=\"MultiDCP_AE_loss\")\n",
    "else:\n",
    "    os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
    "\n",
    "# check cuda\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Use GPU: %s\" % torch.cuda.is_available())\n",
    "\n",
    "def model_training(args, model, data, ae_data, metrics_summary):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "    best_dev_pearson = float(\"-inf\")\n",
    "\n",
    "    for epoch in range(args.max_epoch):\n",
    "    \n",
    "        print(\"Iteration %d:\" % (epoch))\n",
    "        print_lr(optimizer)\n",
    "        model.train()\n",
    "        data_save = False\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for i, (feature, label, _) in enumerate(ae_data.train_dataloader()):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            #### the auto encoder step doesn't need other input rather than feature\n",
    "            predict, cell_hidden_ = model(input_cell_gex=feature, job_id = 'ae', epoch = epoch)\n",
    "            loss_t = model.loss(label, predict)\n",
    "            loss_t.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss_t.item()\n",
    "\n",
    "        print('AE Train loss:')\n",
    "        print(epoch_loss/(i+1))\n",
    "        if USE_WANDB:\n",
    "            wandb.log({'AE Train loss': epoch_loss/(i+1)}, step = epoch)\n",
    "\n",
    "        model.eval()\n",
    "        epoch_loss = 0\n",
    "        lb_np = np.empty([0, 978])\n",
    "        predict_np = np.empty([0, 978])\n",
    "        with torch.no_grad():\n",
    "            for i, (feature, label, _) in enumerate(ae_data.val_dataloader()):\n",
    "                predict, _ = model(input_cell_gex=feature, job_id = 'ae', epoch = epoch)\n",
    "                loss = model.loss(label, predict)\n",
    "                epoch_loss += loss.item()\n",
    "                lb_np = np.concatenate((lb_np, label.cpu().numpy()), axis=0)\n",
    "                predict_np = np.concatenate((predict_np, predict.cpu().numpy()), axis=0)\n",
    "            validation_epoch_end(epoch_loss = epoch_loss, lb_np = lb_np, \n",
    "                                predict_np = predict_np, steps_per_epoch = i+1, \n",
    "                                epoch = epoch, metrics_summary = metrics_summary,\n",
    "                                job = 'ae', USE_WANDB = USE_WANDB)\n",
    "        \n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for i, (ft, lb, _) in enumerate(data.train_dataloader()):\n",
    "            drug = ft['drug']\n",
    "            mask = ft['mask']\n",
    "            cell_feature = ft['cell_id']\n",
    "            pert_idose = ft['pert_idose']\n",
    "            optimizer.zero_grad()\n",
    "            predict, cell_hidden_ = model(input_cell_gex=cell_feature, input_drug = drug, \n",
    "                                        input_gene = data.gene, mask = mask,\n",
    "                                        input_pert_idose = pert_idose, \n",
    "                                        job_id = 'perturbed', epoch = epoch)\n",
    "            loss_t = model.loss(lb, predict)\n",
    "            loss_t.backward()\n",
    "            optimizer.step()\n",
    "            if i == 1:\n",
    "                print('__________________________pertubed input__________________________')\n",
    "                print(cell_feature)\n",
    "                print('__________________________pertubed hidden__________________________')\n",
    "                print(cell_hidden_)\n",
    "                print('__________________________pertubed predicts__________________________')\n",
    "                print(cell_hidden_)\n",
    "            epoch_loss += loss_t.item()\n",
    "        print('Perturbed gene expression profile Train loss:')\n",
    "        print(epoch_loss/(i+1))\n",
    "        if USE_WANDB:\n",
    "            wandb.log({'Perturbed gene expression profile Train loss': epoch_loss/(i+1)}, step = epoch)\n",
    "\n",
    "        model.eval()\n",
    "        epoch_loss = 0\n",
    "        lb_np = np.empty([0, 978])\n",
    "        predict_np = np.empty([0, 978])\n",
    "        with torch.no_grad():\n",
    "            for i, (ft, lb, _) in enumerate(data.val_dataloader()):\n",
    "                drug = ft['drug']\n",
    "                mask = ft['mask']\n",
    "                cell_feature = ft['cell_id']\n",
    "                pert_idose = ft['pert_idose']\n",
    "                predict, _ = model(input_cell_gex=cell_feature, input_drug = drug, \n",
    "                                input_gene = data.gene, mask = mask,\n",
    "                                input_pert_idose = pert_idose, \n",
    "                                job_id = 'perturbed', epoch = epoch)\n",
    "                loss = model.loss(lb, predict)\n",
    "                epoch_loss += loss.item()\n",
    "                lb_np = np.concatenate((lb_np, lb.cpu().numpy()), axis=0)\n",
    "                predict_np = np.concatenate((predict_np, predict.cpu().numpy()), axis=0)\n",
    "            validation_epoch_end(epoch_loss = epoch_loss, lb_np = lb_np, \n",
    "                                predict_np = predict_np, steps_per_epoch = i+1, \n",
    "                                epoch = epoch, metrics_summary = metrics_summary,\n",
    "                                job = 'perturbed', USE_WANDB = USE_WANDB)\n",
    "\n",
    "            if best_dev_pearson < metrics_summary['pearson_list_perturbed_dev'][-1] or epoch == 1:\n",
    "                # data_save = True\n",
    "                best_dev_pearson = metrics_summary['pearson_list_perturbed_dev'][-1]\n",
    "                torch.save(model.state_dict(), 'best_multidcp_ae_model_1.pt')\n",
    "        # if not data_save or (epoch < 400 and epoch != 1):\n",
    "        #     continue\n",
    "        epoch_loss = 0\n",
    "        lb_np = np.empty([0, 978])\n",
    "        predict_np = np.empty([0, 978])\n",
    "        hidden_np = np.empty([0, 50])\n",
    "        with torch.no_grad():\n",
    "            for i, (feature, label, _) in enumerate(ae_data.test_dataloader()):\n",
    "                predict, hidden = model(input_cell_gex=feature, job_id = 'ae')\n",
    "                loss = model.loss(label, predict)\n",
    "                epoch_loss += loss.item()\n",
    "                lb_np = np.concatenate((lb_np, label.cpu().numpy()), axis=0)\n",
    "                predict_np = np.concatenate((predict_np, predict.cpu().numpy()), axis=0)\n",
    "                hidden_np = np.concatenate((hidden_np, hidden.cpu().numpy()), axis=0)\n",
    "\n",
    "            if data_save:\n",
    "                test_ae_label_file = pd.read_csv(args.ae_label_file + '_test.csv', index_col=0)\n",
    "                hidden_df = pd.DataFrame(hidden_np, index = list(test_ae_label_file.index), columns = [x for x in range(50)])\n",
    "                print('++++++++++++++++++++++++++++Write hidden state out++++++++++++++++++++++++++++++++')\n",
    "                hidden_df.to_csv(args.hidden_repr_result_for_testset)\n",
    "\n",
    "            test_epoch_end(epoch_loss = epoch_loss, lb_np = lb_np, \n",
    "                                predict_np = predict_np, steps_per_epoch = i+1, \n",
    "                                epoch = epoch, metrics_summary = metrics_summary,\n",
    "                                job = 'ae', USE_WANDB = USE_WANDB)\n",
    "\n",
    "        epoch_loss = 0\n",
    "        lb_np_ls = []\n",
    "        predict_np_ls = []\n",
    "        hidden_np_ls = []\n",
    "        with torch.no_grad():\n",
    "            for i, (ft, lb, _) in enumerate(tqdm(data.test_dataloader())):\n",
    "                drug = ft['drug']\n",
    "                mask = ft['mask']\n",
    "                cell_feature = ft['cell_id']\n",
    "                pert_idose = ft['pert_idose']\n",
    "                predict, cells_hidden_repr = model(input_cell_gex=cell_feature, input_drug = drug, \n",
    "                                                input_gene = data.gene, mask = mask,\n",
    "                                                input_pert_idose = pert_idose, job_id = 'perturbed')\n",
    "                loss = model.loss(lb, predict)\n",
    "                epoch_loss += loss.item()\n",
    "                lb_np_ls.append(lb.cpu().numpy()) \n",
    "                predict_np_ls.append(predict.cpu().numpy()) \n",
    "                hidden_np_ls.append(cells_hidden_repr.cpu().numpy()) \n",
    "\n",
    "            lb_np = np.concatenate(lb_np_ls, axis = 0)\n",
    "            predict_np = np.concatenate(predict_np_ls, axis = 0)\n",
    "            hidden_np = np.concatenate(hidden_np_ls, axis = 0)\n",
    "            if data_save:\n",
    "                sorted_test_input = pd.read_csv(args.test_file).sort_values(['pert_id', 'pert_type', 'cell_feature', 'pert_idose'])\n",
    "                genes_cols = sorted_test_input.columns[5:]\n",
    "                assert sorted_test_input.shape[0] == predict_np.shape[0]\n",
    "                predict_df = pd.DataFrame(predict_np, index = sorted_test_input.index, columns = genes_cols)\n",
    "                ground_truth_df = pd.DataFrame(lb_np, index = sorted_test_input.index, columns = genes_cols)\n",
    "                result_df = pd.concat([sorted_test_input.iloc[:, :5], predict_df], axis = 1)\n",
    "                ground_truth_df = pd.concat([sorted_test_input.iloc[:,:5], ground_truth_df], axis = 1)\n",
    "\n",
    "                print(\"=====================================write out data=====================================\")\n",
    "                if epoch == 1:\n",
    "                    result_df.loc[[x for x in range(len(result_df)//100)],:].to_csv('../MultiDCP/data/teacher_student/second_AD_dataset_results.csv', index = False)\n",
    "                    # hidden_df.loc[[x for x in range(len(hidden_df))],:].to_csv('../MultiDCP/data/AMPAD_data/second_AD_dataset_hidden_representation.csv', index = False)\n",
    "                else:\n",
    "                    result_df.loc[[x for x in range(len(result_df))],:].to_csv(args.predicted_result_for_testset, index = False)\n",
    "                # hidden_df.loc[[x for x in range(len(hidden_df))],:].to_csv(args.hidden_repr_result_for_testset, index = False)\n",
    "                # ground_truth_df.loc[[x for x in range(len(result_df))],:].to_csv('../MultiDCP/data/side_effect/test_for_same.csv', index = False)\n",
    "\n",
    "            test_epoch_end(epoch_loss = epoch_loss, lb_np = lb_np, \n",
    "                                predict_np = predict_np, steps_per_epoch = i+1, \n",
    "                                epoch = epoch, metrics_summary = metrics_summary,\n",
    "                                job = 'perturbed', USE_WANDB = USE_WANDB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='MultiDCP AE')\n",
    "\n",
    "parser.add_argument('--drug_file', type=str, default=\"/raid/home/joshua/MultiDCP/MultiDCP/data/all_drugs_l1000.csv\")\n",
    "parser.add_argument('--gene_file', type=str, default=\"/raid/home/joshua/MultiDCP/MultiDCP/data/gene_vector.csv\")\n",
    "parser.add_argument('--train_file', type=str, default=\"/raid/home/joshua/MultiDCP/MultiDCP/data/pert_transcriptom/signature_train_cell_1.csv\")\n",
    "parser.add_argument('--dev_file', type=str, default=\"/raid/home/joshua/MultiDCP/MultiDCP/data/pert_transcriptom/signature_dev_cell_1.csv\")\n",
    "parser.add_argument('--test_file', type=str, default=\"/raid/home/joshua/MultiDCP/MultiDCP/data/pert_transcriptom/signature_test_cell_1.csv\")\n",
    "parser.add_argument('--batch_size', type = int, default=64)\n",
    "parser.add_argument('--ae_input_file', type=str, default=\"/raid/home/joshua/MultiDCP/MultiDCP/data/gene_expression_for_ae/gene_expression_combat_norm_978_split4\")\n",
    "parser.add_argument('--ae_label_file', type=str, default=\"/raid/home/joshua/MultiDCP/MultiDCP/data/gene_expression_for_ae/gene_expression_combat_norm_978_split4\")\n",
    "parser.add_argument('--cell_ge_file', type=str, default=\"/raid/home/joshua/MultiDCP/MultiDCP/data/adjusted_ccle_tcga_ad_tpm_log2.csv\", help='the file which used to map cell line to gene expression file')\n",
    "parser.add_argument('--max_epoch', type = int, default=3) # default is 500\n",
    "parser.add_argument('--predicted_result_for_testset', type=str, default=\"/raid/home/joshua/MultiDCP/MultiDCP/data/teacher_student/teach_stu_perturbedGX.csv\", help = \"the file directory to save the predicted test dataframe\")\n",
    "parser.add_argument('--hidden_repr_result_for_testset', type=str, default=\"/raid/home/joshua/MultiDCP/MultiDCP/data/teacher_student/teach_stu_perturbedGX_hidden.csv\", help = \"the file directory to save the test data hidden representation dataframe\")\n",
    "parser.add_argument('--all_cells', type=str, default=\"/raid/home/joshua/MultiDCP/MultiDCP/data/ccle_tcga_ad_cells.p\")\n",
    "parser.add_argument('--dropout', type=float, default=0.3)\n",
    "parser.add_argument('--linear_encoder_flag', dest = 'linear_encoder_flag', action='store_true', default=False, \\\n",
    "                    help = 'whether the cell embedding layer only have linear layers')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "all_cells = list(pickle.load(open(args.all_cells, 'rb')))\n",
    "DATA_FILTER = {\"time\": \"24H\", \"pert_id\": ['BRD-U41416256', 'BRD-U60236422','BRD-U01690642','BRD-U08759356','BRD-U25771771', 'BRD-U33728988', 'BRD-U37049823',\n",
    "            'BRD-U44618005', 'BRD-U44700465','BRD-U51951544', 'BRD-U66370498','BRD-U68942961', 'BRD-U73238814',\n",
    "            'BRD-U82589721','BRD-U86922168','BRD-U97083655'],\n",
    "        \"pert_type\": [\"trt_cp\"],\n",
    "        \"cell_id\": all_cells,# ['A549', 'MCF7', 'HCC515', 'HEPG2', 'HS578T', 'PC3', 'SKBR3', 'MDAMB231', 'JURKAT', 'A375', 'BT20', 'HELA', 'HT29', 'HA1E', 'YAPC'],\n",
    "        \"pert_idose\": [\"0.04 um\", \"0.12 um\", \"0.37 um\", \"1.11 um\", \"3.33 um\", \"10.0 um\"]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Summary (printing from data_utils):\n",
      "['trt_cp']\n",
      "['A375', 'BT20', 'HA1E', 'HCC515', 'HEPG2', 'HS578T', 'HT29', 'JURKAT', 'PC3', 'YAPC']\n",
      "['0.04 um', '0.12 um', '0.37 um', '1.11 um', '10.0 um', '3.33 um']\n",
      "Feature Summary (printing from data_utils):\n",
      "['trt_cp']\n",
      "['MCF7', 'SKBR3']\n",
      "['0.04 um', '0.12 um', '0.37 um', '1.11 um', '10.0 um', '3.33 um']\n",
      "Feature Summary (printing from data_utils):\n",
      "['trt_cp']\n",
      "['A549', 'HELA', 'MDAMB231']\n",
      "['0.04 um', '0.12 um', '0.37 um', '1.11 um', '10.0 um', '3.33 um']\n",
      "#Train: 2641\n",
      "#Dev: 450\n",
      "#Test: 503\n",
      "#Train AE: 13053\n",
      "#Dev AE: 923\n",
      "#Test AE: 13053\n",
      "--------------with linear encoder: False--------------\n",
      "Initialized multidcp's weight............\n",
      "Iteration 0:\n",
      "============current learning rate is 0.0002\n",
      "AE Train loss:\n",
      "1.8564765752826364\n",
      "ae Dev loss:\n",
      "0.6604237909347733\n",
      "ae RMSE: 0.8122462571051241\n",
      "ae Pearson's correlation: 0.20437006351796647\n",
      "ae Spearman's correlation: 0.2226982444748925\n",
      "ae Precision@10 Positive: 0.1783315276273023\n",
      "ae Precision@10 Negative: 0.18569880823401955\n",
      "ae Precision@20 Positive: 0.17264355362946912\n",
      "ae Precision@20 Negative: 0.17903575297941496\n",
      "ae Precision@50 Positive: 0.15945828819068256\n",
      "ae Precision@50 Negative: 0.172762730227519\n",
      "ae Precision@100 Positive: 0.15150595882990248\n",
      "ae Precision@100 Negative: 0.17234019501625134\n",
      "__________________________pertubed input__________________________\n",
      "tensor([[-0.0318, -0.2737,  1.1385,  ...,  1.3416,  2.0335,  1.0423],\n",
      "        [-0.0318,  2.1183,  1.3796,  ..., -0.0904,  1.3894,  1.8758],\n",
      "        [-0.0318,  3.6848,  0.1213,  ...,  0.9663,  0.8978,  1.3777],\n",
      "        ...,\n",
      "        [-0.0318, -0.1737, -0.3265,  ..., -0.7213, -1.3400,  0.1203],\n",
      "        [-0.0318, -0.1737, -0.3265,  ..., -0.7213, -1.3400,  0.1203],\n",
      "        [-0.0318,  0.0579,  1.4631,  ..., -0.1915,  0.7644,  0.9007]],\n",
      "       dtype=torch.float64)\n",
      "__________________________pertubed hidden__________________________\n",
      "tensor([[ 0.2313, -0.0153, -0.0147,  ..., -0.0155,  0.2287, -0.0141],\n",
      "        [ 0.2305,  0.2173,  0.2307,  ..., -0.0151, -0.0151,  0.0124],\n",
      "        [-0.0153,  0.0656,  0.2302,  ..., -0.0155,  0.2308, -0.0152],\n",
      "        ...,\n",
      "        [-0.0142, -0.0148,  0.2300,  ..., -0.0151, -0.0151,  0.2297],\n",
      "        [-0.0154,  0.1538,  0.2306,  ..., -0.0120, -0.0140,  0.1826],\n",
      "        [ 0.2276,  0.2308,  0.0804,  ..., -0.0153,  0.2309,  0.0466]],\n",
      "       dtype=torch.float64, grad_fn=<MaxBackward0>)\n",
      "__________________________pertubed predicts__________________________\n",
      "tensor([[ 0.2313, -0.0153, -0.0147,  ..., -0.0155,  0.2287, -0.0141],\n",
      "        [ 0.2305,  0.2173,  0.2307,  ..., -0.0151, -0.0151,  0.0124],\n",
      "        [-0.0153,  0.0656,  0.2302,  ..., -0.0155,  0.2308, -0.0152],\n",
      "        ...,\n",
      "        [-0.0142, -0.0148,  0.2300,  ..., -0.0151, -0.0151,  0.2297],\n",
      "        [-0.0154,  0.1538,  0.2306,  ..., -0.0120, -0.0140,  0.1826],\n",
      "        [ 0.2276,  0.2308,  0.0804,  ..., -0.0153,  0.2309,  0.0466]],\n",
      "       dtype=torch.float64, grad_fn=<MaxBackward0>)\n",
      "Perturbed gene expression profile Train loss:\n",
      "3.6284179395935623\n",
      "perturbed Dev loss:\n",
      "3.1095501265911714\n",
      "perturbed RMSE: 1.8108133998876086\n",
      "perturbed Pearson's correlation: 0.21690525840223074\n",
      "perturbed Spearman's correlation: 0.2071750256260887\n",
      "perturbed Precision@10 Positive: 0.14955555555555558\n",
      "perturbed Precision@10 Negative: 0.2313333333333333\n",
      "perturbed Precision@20 Positive: 0.14200000000000002\n",
      "perturbed Precision@20 Negative: 0.2451111111111111\n",
      "perturbed Precision@50 Positive: 0.1264888888888889\n",
      "perturbed Precision@50 Negative: 0.22506666666666666\n",
      "perturbed Precision@100 Positive: 0.11868888888888889\n",
      "perturbed Precision@100 Negative: 0.19348888888888893\n",
      "ae Test loss:\n",
      "1.6755084521922863\n",
      "ae RMSE: 1.2944769619428358\n",
      "ae Pearson's correlation: 0.27161663192570223\n",
      "ae Spearman's correlation: 0.28755686182131357\n",
      "ae Precision@10 Positive: 0.20459664444955186\n",
      "ae Precision@10 Negative: 0.23652034015168927\n",
      "ae Precision@20 Positive: 0.18742051635639317\n",
      "ae Precision@20 Negative: 0.22863326438366657\n",
      "ae Precision@50 Positive: 0.16336321152225544\n",
      "ae Precision@50 Negative: 0.20722132843024596\n",
      "ae Precision@100 Positive: 0.14427870987512448\n",
      "ae Precision@100 Negative: 0.186341837125565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:27<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturbed Test loss:\n",
      "3.4031674320182934\n",
      "perturbed RMSE: 1.8452449119152388\n",
      "perturbed Pearson's correlation: 0.1654790894245767\n",
      "perturbed Spearman's correlation: 0.158594388344632\n",
      "perturbed Precision@10 Positive: 0.14731610337972167\n",
      "perturbed Precision@10 Negative: 0.1996023856858847\n",
      "perturbed Precision@20 Positive: 0.1466202783300199\n",
      "perturbed Precision@20 Negative: 0.21202783300198808\n",
      "perturbed Precision@50 Positive: 0.12656063618290259\n",
      "perturbed Precision@50 Negative: 0.18990059642147122\n",
      "perturbed Precision@100 Positive: 0.11296222664015905\n",
      "perturbed Precision@100 Negative: 0.16836978131212724\n",
      "Iteration 1:\n",
      "============current learning rate is 0.0002\n",
      "AE Train loss:\n",
      "1.5547581116921456\n",
      "ae Dev loss:\n",
      "0.5944412588000354\n",
      "ae RMSE: 0.7713868982042773\n",
      "ae Pearson's correlation: 0.3903308332579248\n",
      "ae Spearman's correlation: 0.3945275050466697\n",
      "ae Precision@10 Positive: 0.3872156013001083\n",
      "ae Precision@10 Negative: 0.32979414951245933\n",
      "ae Precision@20 Positive: 0.3598049837486457\n",
      "ae Precision@20 Negative: 0.32128927410617547\n",
      "ae Precision@50 Positive: 0.310899241603467\n",
      "ae Precision@50 Negative: 0.2953629469122427\n",
      "ae Precision@100 Positive: 0.2701733477789816\n",
      "ae Precision@100 Negative: 0.26250270855904656\n",
      "__________________________pertubed input__________________________\n",
      "tensor([[-0.0318, -0.2737,  1.1385,  ...,  1.3416,  2.0335,  1.0423],\n",
      "        [-0.0318,  2.1183,  1.3796,  ..., -0.0904,  1.3894,  1.8758],\n",
      "        [-0.0318, -0.1737, -0.3265,  ..., -0.7213, -1.3400,  0.1203],\n",
      "        ...,\n",
      "        [-0.0318,  0.0579,  1.4631,  ..., -0.1915,  0.7644,  0.9007],\n",
      "        [-0.0318,  4.7264,  2.2007,  ...,  1.3681, -0.1820,  1.1991],\n",
      "        [-0.0318,  0.0579,  1.4631,  ..., -0.1915,  0.7644,  0.9007]],\n",
      "       dtype=torch.float64)\n",
      "__________________________pertubed hidden__________________________\n",
      "tensor([[ 0.0311,  0.2914, -0.0373,  ..., -0.0390,  0.0647, -0.0377],\n",
      "        [ 0.2924,  0.0462, -0.0382,  ...,  0.0812, -0.0385, -0.0383],\n",
      "        [ 0.2895, -0.0362,  0.3094,  ..., -0.0387,  0.2989,  0.2950],\n",
      "        ...,\n",
      "        [ 0.3061,  0.3038,  0.2453,  ..., -0.0371,  0.1564, -0.0382],\n",
      "        [ 0.3055,  0.2980,  0.3093,  ...,  0.2998, -0.0375,  0.3065],\n",
      "        [ 0.2492,  0.3020,  0.3078,  ..., -0.0141,  0.3012, -0.0377]],\n",
      "       dtype=torch.float64, grad_fn=<MaxBackward0>)\n",
      "__________________________pertubed predicts__________________________\n",
      "tensor([[ 0.0311,  0.2914, -0.0373,  ..., -0.0390,  0.0647, -0.0377],\n",
      "        [ 0.2924,  0.0462, -0.0382,  ...,  0.0812, -0.0385, -0.0383],\n",
      "        [ 0.2895, -0.0362,  0.3094,  ..., -0.0387,  0.2989,  0.2950],\n",
      "        ...,\n",
      "        [ 0.3061,  0.3038,  0.2453,  ..., -0.0371,  0.1564, -0.0382],\n",
      "        [ 0.3055,  0.2980,  0.3093,  ...,  0.2998, -0.0375,  0.3065],\n",
      "        [ 0.2492,  0.3020,  0.3078,  ..., -0.0141,  0.3012, -0.0377]],\n",
      "       dtype=torch.float64, grad_fn=<MaxBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19307/4251171043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mmodel_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mae_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mreport_final_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperturbed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19307/1817239853.py\u001b[0m in \u001b[0;36mmodel_training\u001b[0;34m(args, model, data, ae_data, metrics_summary)\u001b[0m\n\u001b[1;32m     64\u001b[0m                                         \u001b[0minput_gene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                                         \u001b[0minput_pert_idose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpert_idose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                                         job_id = 'perturbed', epoch = epoch)\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mloss_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mloss_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/home/joshua/anaconda3/envs/joshua_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/home/joshua/MultiDCP/MultiDCP/models/multidcp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_cell_gex, input_drug, input_gene, mask, input_pert_idose, job_id, epoch)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjob_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'perturbed'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             return self.perturbed_trans(input_cell_gex, input_drug, input_gene, mask, \n\u001b[0;32m--> 383\u001b[0;31m                         input_pert_idose, epoch)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_cell_gex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/home/joshua/MultiDCP/MultiDCP/models/multidcp.py\u001b[0m in \u001b[0;36mperturbed_trans\u001b[0;34m(self, input_cell_gex, input_drug, input_gene, mask, input_pert_idose, epoch)\u001b[0m\n\u001b[1;32m    388\u001b[0m                         input_pert_idose, epoch):\n\u001b[1;32m    389\u001b[0m         out, cell_hidden_ = self.multidcp(input_drug, input_gene, mask, input_cell_gex,\n\u001b[0;32m--> 390\u001b[0;31m                                                 input_pert_idose, epoch = epoch)\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;31m# out = [batch * num_gene * hid_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/home/joshua/anaconda3/envs/joshua_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/home/joshua/MultiDCP/MultiDCP/models/multidcp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_drug, input_gene, mask, input_cell_gex, input_pert_idose, epoch)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mdrug_gene_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrug_gene_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpert_idose_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;31m# drug_gene_embed = [batch * num_gene * (drug_embed + gene_embed + pert_type_embed + cell_id_embed + pert_idose_embed)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mdrug_gene_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrug_gene_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;31m## First layer of the mlp layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/home/joshua/anaconda3/envs/joshua_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/home/joshua/anaconda3/envs/joshua_base/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/home/joshua/anaconda3/envs/joshua_base/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "ae_data = datareader.AEDataLoader(device, args)\n",
    "data = datareader.PerturbedDataLoader(DATA_FILTER, device, args)\n",
    "ae_data.setup()\n",
    "data.setup()\n",
    "print('#Train: %d' % len(data.train_data))\n",
    "print('#Dev: %d' % len(data.dev_data))\n",
    "print('#Test: %d' % len(data.test_data))\n",
    "print('#Train AE: %d' % len(ae_data.train_data))\n",
    "print('#Dev AE: %d' % len(ae_data.dev_data))\n",
    "print('#Test AE: %d' % len(ae_data.test_data))\n",
    "\n",
    "# parameters initialization\n",
    "model_param_registry = initialize_model_registry()\n",
    "model_param_registry.update({'num_gene': np.shape(data.gene)[0],\n",
    "                            'pert_idose_input_dim': len(DATA_FILTER['pert_idose']),\n",
    "                            'dropout': args.dropout, \n",
    "                            'linear_encoder_flag': args.linear_encoder_flag}) \n",
    "\n",
    "# model creation\n",
    "print('--------------with linear encoder: {0!r}--------------'.format(args.linear_encoder_flag))\n",
    "model = multidcp.MultiDCP_AE(device=device, model_param_registry=model_param_registry)\n",
    "model.init_weights(pretrained = False)\n",
    "model.to(device)\n",
    "model = model.double()     \n",
    "\n",
    "if USE_WANDB:\n",
    "    wandb.watch(model, log=\"all\")\n",
    "\n",
    "# training\n",
    "metrics_summary = defaultdict(\n",
    "    pearson_list_ae_dev = [],\n",
    "    pearson_list_ae_test = [],\n",
    "    pearson_list_perturbed_dev = [],\n",
    "    pearson_list_perturbed_test = [],\n",
    "    spearman_list_ae_dev = [],\n",
    "    spearman_list_ae_test = [],\n",
    "    spearman_list_perturbed_dev = [],\n",
    "    spearman_list_perturbed_test = [],\n",
    "    rmse_list_ae_dev = [],\n",
    "    rmse_list_ae_test = [],\n",
    "    rmse_list_perturbed_dev = [],\n",
    "    rmse_list_perturbed_test = [],\n",
    "    precisionk_list_ae_dev = [],\n",
    "    precisionk_list_ae_test = [],\n",
    "    precisionk_list_perturbed_dev = [],\n",
    "    precisionk_list_perturbed_test = [],\n",
    ")\n",
    "\n",
    "model_training(args, model, data, ae_data, metrics_summary)\n",
    "report_final_results(metrics_summary, ae = True, perturbed = True)\n",
    "end_time = datetime.now()\n",
    "#torch.save(model, './savedmodel_06232022.pt')\n",
    "pickle.dump(model, open('model_06232022_ipynb.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model_06232022_ipynb.pkl','wb'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae12911e779d354bcb5c9e70a5dc1988b39837b018b3918cf9b62b74d28f4ab0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('joshua_base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
